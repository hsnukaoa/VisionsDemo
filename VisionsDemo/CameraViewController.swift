//
//  CameraViewController.swift
//  VisionsDemo
//
//  Created by å®‡ç”°å·èˆªå¤ª on 2025/10/31.
//


import UIKit
import AVFoundation

class CameraViewController: UIViewController, AVCapturePhotoCaptureDelegate {
    
    //å¿…é ˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    //å‹•ç”»ã®å ´åˆã¯ã€AVCapturePhotoOutputã®ä»£ã‚ã‚Šã«AVCaptureVideoDataOutput()ã‚’è¨­å®šã™ã‚‹
    var captureSession = AVCaptureSession()
    var previewLayer:AVCaptureVideoPreviewLayer!
    var photoOutput = AVCapturePhotoOutput()
    
    // SwiftUIå´ã«ç”»åƒã‚’è¿”ã™ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ£
    var onPhotoCaptured: ((UIImage) -> Void)?
    var onDetectLeftEyeImage: ((UIImage) -> Void)?
    
    let vision = VisionController()
    
    //ç”»é¢ãŒåˆã‚ã¦è¡¨ç¤ºã•ã‚ŒãŸã¨ãã«å‘¼ã°ã‚Œã‚‹é–¢æ•°ã€‚ã“ã“ã§åˆæœŸè¨­å®šã‚’ã—ã¦ã„ã‚‹
    override func viewDidLoad() {
        super.viewDidLoad()
        //ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã€æ˜ åƒã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«æ˜ ã™ã‚ˆã†ã«ã™ã‚‹
        setupCamera()
        //æ’®å½±ãƒœã‚¿ãƒ³ã‚’ä½œã£ã¦é…ç½®ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹
        setupUI()
    }
    
    //MARK: ã‚«ãƒ¡ãƒ©ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    private func setupCamera() {
        captureSession = AVCaptureSession()
        //é™æ­¢ç”»æ’®å½±ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š
        captureSession.sessionPreset = .photo
        
        // ãƒ•ãƒ­ãƒ³ãƒˆã‚«ãƒ¡ãƒ©ã‚’å–å¾—ã€‚è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã—ã¦çµ‚äº†
        guard let camera = AVCaptureDevice.default(.builtInWideAngleCamera,for: .video,position: .front) else {
            print("Front camera not found")
            return
        }
        
        do {
            let input = try AVCaptureDeviceInput(device: camera)
            if captureSession.canAddInput(input) {
                captureSession.addInput(input)
            }
            
            // å‡ºåŠ›è¨­å®š
            photoOutput = AVCapturePhotoOutput()
            if captureSession.canAddOutput(photoOutput) {
                captureSession.addOutput(photoOutput)
            }
            
            // ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¨­å®š
            previewLayer = AVCaptureVideoPreviewLayer(session: captureSession)
            previewLayer.videoGravity = .resizeAspectFill
            previewLayer.frame = view.bounds
            view.layer.addSublayer(previewLayer)
            
            //ã‚«ãƒ¡ãƒ©èµ·å‹•å‡¦ç†(DispatchQueueã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¹ãƒ¬ãƒƒãƒ‰ã«ç§»å‹•ã—ã€UIã®ãƒ•ãƒªãƒ¼ã‚ºã‚’é˜²ã)
            DispatchQueue.global(qos: .userInitiated).async {
                self.captureSession.startRunning()
            }
        } catch {
            print("Camera setup error: \(error)")
        }
    }
    
    //MARK: UIã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    private func setupUI() {
        let shutterButton = UIButton(type: .system)
        //ãƒœã‚¿ãƒ³ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ä½œæˆ
        shutterButton.setTitle("ğŸ“¸ æ’®å½±", for: .normal)
        shutterButton.titleLabel?.font = UIFont.systemFont(ofSize: 22, weight: .semibold)
        shutterButton.backgroundColor = UIColor.white.withAlphaComponent(0.6)
        shutterButton.layer.cornerRadius = 30
        shutterButton.translatesAutoresizingMaskIntoConstraints = false
        //ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã«takePhotoé–¢æ•°ãŒå‘¼ã°ã‚Œã‚‹ã‚ˆã†ã«è¨­å®š
        shutterButton.addTarget(self, action: #selector(takePhoto), for: .touchUpInside)
        view.addSubview(shutterButton)
        
        //ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’ãƒ«ãƒ¼ãƒ«ã§è¡¨ç¾ã™ã‚‹ä»•çµ„ã¿
        NSLayoutConstraint.activate([
            shutterButton.centerXAnchor.constraint(equalTo: view.centerXAnchor),
            shutterButton.bottomAnchor.constraint(equalTo: view.bottomAnchor, constant: -60),
            shutterButton.widthAnchor.constraint(equalToConstant: 100),
            shutterButton.heightAnchor.constraint(equalToConstant: 60)
        ])
    }
    
    @objc private func takePhoto() {
        //å†™çœŸã‚’æ’®ã‚‹æ“ä½œã‚’å®Ÿè¡Œ
        let settings = AVCapturePhotoSettings()
        settings.flashMode = .off
        photoOutput.capturePhoto(with: settings, delegate: self)
    }
    
    
    //ç”»é¢ãŒé–‰ã˜ã‚‰ã‚ŒãŸæ™‚ã®å¾Œå‡¦ç†æ‹…å½“
    override func viewWillDisappear(_ animated: Bool) {
        super.viewWillDisappear(animated)
        //ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã—ã¦ã€ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã™ã‚‹
        captureSession.stopRunning()
    }
    
    func photoOutput(_ output: AVCapturePhotoOutput,
                     didFinishProcessingPhoto photo: AVCapturePhoto,
                     error: Error?) {
        //ã“ã“ã§æ’®å½±çµæœã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰UIImageã‚’ä½œã‚Šå‡ºã—ã¦ã„ã‚‹
        guard error == nil,
              let data = photo.fileDataRepresentation(),
              let image = UIImage(data: data) else {
            print("Failed to capture photo")
            return
        }
        
        // ä¿®æ­£: completionãƒãƒ³ãƒ‰ãƒ©ã®å¼•æ•°ã‚’ [FaceParts] ã«å¤‰æ›´
        vision.detectAndDrawFaceLandmarks(on: image) { [weak self] facePartsArray in
            DispatchQueue.main.async {
                
                // 1. æ¤œå‡ºçµæœã‹ã‚‰ã€æç”»æ¸ˆã¿ã®ç”»åƒã‚’å–å¾—ã™ã‚‹
                //    (é¡”ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã¯å…ƒã®ç”»åƒã‚’ä½¿ç”¨)
                let imageToSend: UIImage
                if let firstFace = facePartsArray.first {
                    // æœ€åˆã®é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯æç”»æ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨
                    imageToSend = firstFace.originalWithDrawings
                    
                    // ã€å‚è€ƒã€‘ã“ã“ã§åˆ‡ã‚ŠæŠœã‹ã‚ŒãŸãƒ‘ãƒ¼ãƒ„ã‚‚åˆ©ç”¨ã§ãã¾ã™ã€‚ä¾‹:
                    if let leftEye = firstFace.nose {
                        // å·¦ç›®ã®ç”»åƒã‚’ä½¿ã£ã¦ä½•ã‹å‡¦ç†ã‚’è¡Œã†
                        self?.onDetectLeftEyeImage?(leftEye)
                    }
                    
                } else {
                    // é¡”ãŒæ¤œå‡ºã•ã‚Œãªã‹ã£ãŸå ´åˆã¯å…ƒã®ç”»åƒã‚’ä½¿ç”¨
                    imageToSend = image
                }
                
                self?.onPhotoCaptured?(imageToSend)
                self?.dismiss(animated: true)
            }
        }
    }
}

